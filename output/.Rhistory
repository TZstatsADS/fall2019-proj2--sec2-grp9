ggplot(genre.sentiment, aes(x=sentiment.type, y=ratio)) +
geom_col(aes(fill=genre), position="dodge") +
ggtitle("Distribution of emotions across genres") +
theme(plot.title = element_text(hjust = 0.5)) +
ylab("Ratio over the genre") +
xlab("Emotion type")
cos.sim <- data.frame("Jazz" = c(1, jr, jh), "Rock" = c("-", 1.00, rh), "Hip-Hop" = c("-","-",1.00))
row.names(cos.sim) <- c("Jazz", "Rock", "Hip-Hop")
kable(cos.sim) %>%
kable_styling(bootstrap_options = "striped", full_width = F, position = "center")
kable(word.comparison, col.names = c("Genre", "Number of songs", "Number of new words per song")) %>%
kable_styling(bootstrap_options = "striped", full_width = F, position = "center")
knitr::opts_chunk$set(echo = TRUE)
packages.used=c("tidyverse", "devtools", "ngram", "gridExtra", "plotly", "tidytext")
# check packages that need to be installed.
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE)
}
library(tidyverse)
library(devtools)
library(ngram)
library(gridExtra)
library(plotly)
library(tidytext)
devtools::install_github("lchiffon/wordcloud2", force = T, quiet = T)
load("/Users/stefano/Documents/GitHub/fall2019-proj1--StefanoLongo/data/lyrics.RData")
dt_lyrics <- dt_lyrics %>% filter(genre != "Not Available")
dt_lyrics$lyriccount <- sapply(dt_lyrics$lyrics, function(x) wordcount(x, sep = " ", count.function = sum))
dt_lyrics$lyriccount <- sapply(dt_lyrics$lyrics, function(x) wordcount(x, sep = " ", count.function = sum))
dt_lyrics$stemcount <- sapply(dt_lyrics$stemmedwords, function(x) wordcount(x, sep = " ", count.function = sum))
load("/Users/stefano/Documents/GitHub/fall2019-proj1--StefanoLongo/data/lyrics.RData")
dt_lyrics$lyriccount <- sapply(dt_lyrics$lyrics, function(x) wordcount(x, sep = " ", count.function = sum))
dt_lyrics$stemcount <- sapply(dt_lyrics$stemmedwords, function(x) wordcount(x, sep = " ", count.function = sum))
count_genre <-
dt_lyrics %>% group_by(genre) %>% summarise(lyric = mean(lyriccount), stem = mean(stemcount))
# check packages that need to be installed.
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE)
}
library(tidyverse)
library(devtools)
library(ngram)
library(gridExtra)
library(plotly)
library(tidytext)
library(wordcloud2)
load("/Users/stefano/Documents/GitHub/fall2019-proj1--StefanoLongo/data/lyrics.RData")
dt_lyrics$lyriccount <- sapply(dt_lyrics$lyrics, function(x) wordcount(x, sep = " ", count.function = sum))
dt_lyrics$lyriccount <- sapply(dt_lyrics$lyrics, function(x) wordcount(x, sep = " ", count.function = sum))
dt_lyrics$stemcount <- sapply(dt_lyrics$stemmedwords, function(x) wordcount(x, sep = " ", count.function = sum))
knitr::opts_chunk$set(echo = TRUE)
packages.used=c("tidyverse", "devtools", "ngram", "gridExtra", "plotly", "tidytext")
# check packages that need to be installed.
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE)
}
library(tidyverse)
library(devtools)
library(ngram)
library(gridExtra)
library(plotly)
library(tidytext)
library(wordcloud2)
load("/Users/stefano/Documents/GitHub/fall2019-proj1--StefanoLongo/data/lyrics.RData")
dt_lyrics <- dt_lyrics %>% filter(genre != "Not Available")
dt_lyrics$lyriccount <- sapply(dt_lyrics$lyrics, function(x) wordcount(x, sep = " ", count.function = sum))
dt_lyrics$stemcount <- sapply(dt_lyrics$stemmedwords, function(x) wordcount(x, sep = " ", count.function = sum))
?sapply
dt_lyrics$stemcount <- slapply(dt_lyrics$stemmedwords, function(x) wordcount(x, sep = " ", count.function = sum))
dt_lyrics$stemcount <- lapply(dt_lyrics$stemmedwords, function(x) wordcount(x, sep = " ", count.function = sum))
View(dt_lyrics)
knitr::opts_chunk$set(echo = TRUE)
library(tm)
library(tidyverse)
library(tidytext)
library(wordcloud)
library(stargazer)
library(RColorBrewer)
library(topicmodels)
install.packages("topic.models")
install.packages("topicmodels")
library(topicmodels)
load("~/Google Drive (zz2587@columbia.edu)/fall2019-proj1--zzzaaannn-master/output/processed_lyrics.RData")
load("/Users/stefano/Documents/GitHub/fall2019-proj1--StefanoLongo/data/lyrics.RData")
# There are two typos of *year*, so correct them
dt_lyrics[which(dt_lyrics$year==702, arr.ind = TRUE),2] <- 2002
dt_lyrics[which(dt_lyrics$year==112, arr.ind = TRUE),2] <- 1998
glimpse(dt_lyrics)
# use the original lyrics to count words instead of stemmed words
song_wrd_count <- dt_lyrics %>%
select(id,song,year,genre,lyrics) %>%
unnest_tokens(input = lyrics,output = word) %>%
group_by(id) %>%
mutate(wrd_count = n()) %>%
distinct(id,.keep_all = TRUE) %>%
select(-word)
View(dt_lyrics)
load("/Users/stefano/Documents/GitHub/fall2019-proj1--StefanoLongo/data/lyrics.RData")
# There are two typos of *year*, so correct them
dt_lyrics[which(dt_lyrics$year==702, arr.ind = TRUE),2] <- 2002
dt_lyrics[which(dt_lyrics$year==112, arr.ind = TRUE),2] <- 1998
glimpse(dt_lyrics)
View(dt_lyrics)
load("/Users/stefano/Desktop/processed_lyrics.RData")
# There are two typos of *year*, so correct them
dt_lyrics[which(dt_lyrics$year==702, arr.ind = TRUE),2] <- 2002
dt_lyrics[which(dt_lyrics$year==112, arr.ind = TRUE),2] <- 1998
glimpse(dt_lyrics)
# use the original lyrics to count words instead of stemmed words
song_wrd_count <- dt_lyrics %>%
select(id,song,year,genre,lyrics) %>%
unnest_tokens(input = lyrics,output = word) %>%
group_by(id) %>%
mutate(wrd_count = n()) %>%
distinct(id,.keep_all = TRUE) %>%
select(-word)
# compute the average number of words for each year
# using sum of words / sum of number of songs for each year
avg_yr_wrd_count <- song_wrd_count %>%
group_by(year) %>%
summarise(num_song =length(song),
num_wrd = sum(wrd_count)) %>%
mutate(avg_wrd_yr = num_wrd / num_song) %>%
arrange(desc(avg_wrd_yr))
# time series plot of length of lyrics
avg_yr_wrd_count %>%
ggplot(aes(x=year,y = avg_wrd_yr))+
geom_line() +
labs(title = "Time evolution for length of lyrics",
y = "Average Words",x = "")+
theme(plot.title = element_text(hjust = 0.5),
panel.grid.major = element_blank())
# divide lyrics into two parts: 20th century and 21st century by variable year
a <- avg_yr_wrd_count %>%
filter(year <= 2000) %>%
select(avg_wrd_yr) %>%
mutate(century = "20th")
b <- avg_yr_wrd_count %>%
filter(year > 2000) %>%
select(avg_wrd_yr) %>%
mutate(century = "21st")
ab <- rbind(a,b)
ggplot(data = ab,aes(x=century, y = avg_wrd_yr,color = century)) +
geom_boxplot()+
labs(title = "",
y = "Average Words",x = "")+
theme(plot.title = element_text(hjust = 0.5),
panel.grid.major = element_blank())
# divide lyrics into two parts: 20th century and 21st century by variable year
lyrics_before_2000 <- dt_lyrics %>%
filter(year <=2000) %>%
select(stemmedwords)
lyrics_after_2000 <- dt_lyrics %>%
filter(year >2000) %>%
select(stemmedwords)
# compute the frequent terms in the 20th century
before_2000_corpus <- VCorpus(VectorSource(lyrics_before_2000))
before_2000_tdm <- TermDocumentMatrix(before_2000_corpus)
before_2000_m <- as.matrix(before_2000_tdm)
before_2000_freq <- sort(rowSums(before_2000_m),decreasing = TRUE)
ggplot() +
geom_col(aes(x=reorder(names(before_2000_freq)[1:10],before_2000_freq[1:10]),y=before_2000_freq[1:10]),fill = "blue")+
theme(plot.title = element_text(hjust = 0.5),
panel.grid.major = element_blank()) +
xlab("") +
ylab("Terms Count") +
ggtitle("20th Century Most Frequently Used Words in Lyrics") +
coord_flip()
# compute the frequent terms in the 21st century
after_2000_corpus <- VCorpus(VectorSource(lyrics_after_2000))
after_2000_tdm <- TermDocumentMatrix(after_2000_corpus)
after_2000_m <- as.matrix(after_2000_tdm)
after_2000_freq <- sort(rowSums(after_2000_m),decreasing = TRUE)
ggplot() +
geom_col(aes(x=reorder(names(after_2000_freq)[1:10],after_2000_freq[1:10]),y=after_2000_freq[1:10]),fill = "blue")+
theme(legend.position = "none",
plot.title = element_text(hjust = 0.5),
panel.grid.major = element_blank()) +
labs(x = "",y = "Terms Count",
title = "21st Century Most Frequently Used Words in Lyrics" )+
coord_flip()
# put all the lyrics into one corpus with two documents
# one document comes from 20th century, the other comes from 21st century
bb <- paste(lyrics_before_2000, collapse = "")
aa <- paste(lyrics_after_2000,collapse = "")
all <- c(bb,aa)
all_corpus <- VCorpus(VectorSource(all))
# compute frequent terms
all_tdm <- TermDocumentMatrix(all_corpus)
colnames(all_tdm) <- c("20th","21st")
all_m <- as.matrix(all_tdm)
common_words <- subset(all_m,
all_m[,1]>0 & all_m[,2]>0
)
# terms in order with differences
difference <- abs(common_words[, 1] - common_words[, 2])
common_words <- cbind(common_words, difference)
common_words <- common_words[order(common_words[, 3],
decreasing = T), ]
# use proportion of words to compare instead of counts
# 21st century has more songs than 20th century, thus larger number of counts.
# proportion can make plot looks nicer
prop_20 <- common_words[,1]/sum(common_words[,1])
prop_21 <- common_words[,2]/sum(common_words[,2])
common_words_20 <- data.frame(terms =rownames(common_words)[1:25],
count =prop_20[1:25],
century = rep("20th",25))
common_words_21 <- data.frame(terms =rownames(common_words)[1:25],
count = prop_21[1:25],
century = rep("21st",25))
knitr::opts_chunk$set(echo = TRUE)
packages.used=c("tidyverse", "devtools", "ngram", "gridExtra", "plotly", "tidytext")
# check packages that need to be installed.
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE)
}
library(tidyverse)
library(devtools)
library(ngram)
library(gridExtra)
library(plotly)
library(tidytext)
library(wordcloud2)
load('../output/processed_lyrics.RData')
load("/Users/stefano/Downloads/processed_lyrics.RData")
dt_lyrics <- dt_lyrics %>% filter(genre != "Not Available")
dt_lyrics <- dt_lyrics %>% filter(genre != "Not Available")
dt_lyrics$lyriccount <- sapply(dt_lyrics$lyrics, function(x) wordcount(x, sep = " ", count.function = sum))
dt_lyrics$lyriccount <- sapply(dt_lyrics$lyrics, function(x) wordcount(x, sep = " ", count.function = sum))
dt_lyrics$stemcount <- sapply(dt_lyrics$stemmedwords, function(x) wordcount(x, sep = " ", count.function = sum))
count_genre <-
dt_lyrics %>% group_by(genre) %>% summarise(lyric = mean(lyriccount), stem = mean(stemcount))
count_genre_gather <-
gather(count_genre, key = "type", value = "count", -genre) %>% arrange(desc(count))
wordcount1 <- ggplot(count_genre_gather, aes(
x = count,
y = genre,
color = type
)) +
geom_point() + ylab("") + ggtitle("Word count for song lyrics of different genre")
wordcount1 <- ggplotly(wordcount1)
count_genre <-
dt_lyrics %>% group_by(genre) %>% summarise(lyric = mean(lyriccount), stem = mean(stemcount))
count_genre_gather <-
gather(count_genre, key = "type", value = "count", -genre) %>% arrange(desc(count))
wordcount1 <- ggplot(count_genre_gather, aes(
x = count,
y = genre,
color = type
)) +
geom_point() + ylab("") + ggtitle("Word count for song lyrics of different genre")
wordcount1 <- ggplotly(wordcount1)
wordcount1
??ggplotly
install.packages("plotly")
install.packages("plotly")
count_genre$effective_ratio <- count_genre$stem / count_genre$lyric
wordcount2 <- ggplot(count_genre) +
geom_bar(aes(x = reorder(`genre`, effective_ratio), y = effective_ratio), stat = "identity") +   geom_hline(yintercept=mean(dt_lyrics$stemcount/dt_lyrics$lyriccount), linetype="dashed", color = "red")+
coord_flip()+xlab("")+ggtitle("Ratio of effective lyric in different genre")
wordcount2
early <- c(2002,2003,2004,2005,2006)
mid <- c(2007,2008,2009,2010,2011)
recent <- c(2012,2013,2014,2015,2016)
eminem_early <- dt_eminem %>% filter(year %in% early)
dt_hiphop <- dt_lyrics %>% filter(genre == "Hip-Hop")
temp <- dt_hiphop %>% group_by(artist) %>% tally()
lyric_hiphop <- dt_lyrics %>% filter(artist %in% dt_hiphop$artist)
dt_hiphop100 <- dt_hiphop %>% group_by(artist) %>% summarise(lyric_count = mean(lyriccount), n.songs = n()) %>% filter(n.songs >=100)
hh_artist <- ggplot(dt_hiphop100, aes(x=n.songs, y=lyric_count))+
geom_point(aes(fill = artist),
alpha = 0.7, size = 5, shape = 21)+
theme(legend.position = "none") +xlab("number of songs")+ylab("lyric count")+
ggtitle("Popular Hip-Hop artists")
hh_artist
dt_eminem <- dt_lyrics %>% filter(artist=="eminem")
stem_eminem <- strsplit(dt_eminem$stemmedwords, " ") %>% unlist() %>% table() %>% as.data.frame() %>% arrange(desc(Freq))
colnames(stem_eminem) <- c("word","count")
wc_eminem <- wordcloud2(stem_eminem[1:200,],size = 0.6,color = "random-dark")
wc_eminem
stem_eminem$frequency <- stem_eminem$count/sum(stem_eminem$count)
stem_hiphop <- strsplit(lyric_hiphop$stemmedwords, " ") %>% unlist() %>% table() %>% as.data.frame() %>% arrange(desc(Freq))
colnames(stem_hiphop) <- c("word","count")
wc_hiphop <- wordcloud2(stem_hiphop[1:200,],size = 0.6, color = "random-dark")
wc_hiphop
stem_hiphop$frequency <- stem_hiphop$count/sum(stem_hiphop$count)
eminem_sentiment <- stem_eminem %>% inner_join(get_sentiments("bing")) %>% group_by(sentiment) %>% top_n(10, frequency)
eminem_sentiment_plot <-
ggplot(eminem_sentiment,
aes(
x = reorder(word, frequency),
y = frequency,
fill = sentiment
)) +
geom_bar(position = "dodge", stat = "identity") + facet_wrap( ~ sentiment, scales = "free") +
coord_flip() + xlab("") + ggtitle("Top 10 words being used to express each sentiments (Eminem)") + theme(legend.position = "none")
hiphop_sentiment <- stem_hiphop %>% inner_join(get_sentiments("bing")) %>% group_by(sentiment) %>% top_n(10, frequency)
hiphop_sentiment_plot <-
ggplot(hiphop_sentiment,
aes(
x = reorder(word, frequency),
y = frequency,
fill = sentiment
)) +
geom_bar(position = "dodge", stat = "identity") + facet_wrap( ~ sentiment, scales = "free") +
coord_flip() + xlab("") + ggtitle("Top 10 words being used to express each sentiments (Hip-Hop)") + theme(legend.position = "none")
stem_all <- strsplit(dt_lyrics$stemmedwords, " ") %>% unlist() %>% table() %>% as.data.frame() %>% arrange(desc(Freq))
colnames(stem_all) <- c("word","count")
stem_all$frequency <- stem_all$count/sum(stem_all$count)
all_sentiment <- stem_all %>% inner_join(get_sentiments("bing")) %>% group_by(sentiment) %>% top_n(10, frequency)
all_sentiment_plot <-
ggplot(all_sentiment,
aes(
x = reorder(word, frequency),
y = frequency,
fill = sentiment
)) +
geom_bar(position = "dodge", stat = "identity") + facet_wrap( ~ sentiment, scales = "free") +
coord_flip() + xlab("") + ggtitle("Top 10 words being used to express each sentiments (All songs)") + theme(legend.position = "none")
sentiment <- grid.arrange(eminem_sentiment_plot, hiphop_sentiment_plot, all_sentiment_plot, nrow=3)
early <- c(2002,2003,2004,2005,2006)
mid <- c(2007,2008,2009,2010,2011)
recent <- c(2012,2013,2014,2015,2016)
eminem_early <- dt_eminem %>% filter(year %in% early)
eminem_mid <- dt_eminem %>% filter(year %in% mid)
eminem_recent <- dt_eminem %>% filter(year %in% recent)
stem_eminem_early <- strsplit(eminem_early$stemmedwords, " ") %>% unlist() %>% table() %>% as.data.frame() %>% arrange(desc(Freq))
colnames(stem_eminem_early) <- c("word","count")
stem_eminem_early$frequency <- stem_eminem_early$count/sum(stem_eminem_early$count)
stem_eminem_mid <- strsplit(eminem_mid$stemmedwords, " ") %>% unlist() %>% table() %>% as.data.frame() %>% arrange(desc(Freq))
colnames(stem_eminem_mid) <- c("word","count")
stem_eminem_mid$frequency <- stem_eminem_mid$count/sum(stem_eminem_mid$count)
stem_eminem_recent <- strsplit(eminem_recent$stemmedwords, " ") %>% unlist() %>% table() %>% as.data.frame() %>% arrange(desc(Freq))
colnames(stem_eminem_recent) <- c("word","count")
stem_eminem_recent$frequency <- stem_eminem_recent$count/sum(stem_eminem_recent$count)
eminem_top10 <- as.character(stem_eminem[1:10,]$word)
eminem_early_top <- filter(stem_eminem_early, word %in% eminem_top10) %>% select(-count)
eminem_mid_top <- filter(stem_eminem_mid, word %in% eminem_top10)%>% select(-count)
eminem_recent_top <- filter(stem_eminem_recent, word %in% eminem_top10)%>% select(-count)
eminem_alltime_top <- stem_eminem[1:10,] %>% select(-count)
eminem_top10_freq <- Reduce(function(x,y) merge(x = x, y = y, by = "word"),
list(eminem_alltime_top, eminem_early_top, eminem_mid_top, eminem_recent_top))
colnames(eminem_top10_freq) <- c("word" ,"alltime", "early", "mid", "recent")
eminem_top10_freq_gather <- gather(eminem_top10_freq, key = "type", value = "frequency", -word)
eminem_top10_plot <- ggplot(eminem_top10_freq_gather, aes(x = type,y = frequency,fill = type)) +
geom_bar(position = "dodge", stat = "identity") + ylab("") +
facet_wrap( ~word, scales = "free", nrow = 2, ncol = 5) +
theme(axis.title.x = element_blank(),axis.text.x = element_blank(),axis.ticks.x=element_blank())+
ggtitle("Frequency change of top 10 words used across time")+labs(y="")+
theme(panel.spacing.x = unit(1, "cm"), panel.spacing.y = unit(1, "cm"))
eminem_top10_plot <- ggplotly(eminem_top10_plot)
early <- c(2002,2003,2004,2005,2006)
mid <- c(2007,2008,2009,2010,2011)
recent <- c(2012,2013,2014,2015,2016)
eminem_early <- dt_eminem %>% filter(year %in% early)
eminem_mid <- dt_eminem %>% filter(year %in% mid)
eminem_recent <- dt_eminem %>% filter(year %in% recent)
stem_eminem_early <- strsplit(eminem_early$stemmedwords, " ") %>% unlist() %>% table() %>% as.data.frame() %>% arrange(desc(Freq))
colnames(stem_eminem_early) <- c("word","count")
stem_eminem_early$frequency <- stem_eminem_early$count/sum(stem_eminem_early$count)
stem_eminem_mid <- strsplit(eminem_mid$stemmedwords, " ") %>% unlist() %>% table() %>% as.data.frame() %>% arrange(desc(Freq))
colnames(stem_eminem_mid) <- c("word","count")
stem_eminem_mid$frequency <- stem_eminem_mid$count/sum(stem_eminem_mid$count)
stem_eminem_recent <- strsplit(eminem_recent$stemmedwords, " ") %>% unlist() %>% table() %>% as.data.frame() %>% arrange(desc(Freq))
colnames(stem_eminem_recent) <- c("word","count")
stem_eminem_recent$frequency <- stem_eminem_recent$count/sum(stem_eminem_recent$count)
eminem_top10 <- as.character(stem_eminem[1:10,]$word)
eminem_early_top <- filter(stem_eminem_early, word %in% eminem_top10) %>% select(-count)
eminem_mid_top <- filter(stem_eminem_mid, word %in% eminem_top10)%>% select(-count)
eminem_recent_top <- filter(stem_eminem_recent, word %in% eminem_top10)%>% select(-count)
eminem_alltime_top <- stem_eminem[1:10,] %>% select(-count)
eminem_top10_freq <- Reduce(function(x,y) merge(x = x, y = y, by = "word"),
list(eminem_alltime_top, eminem_early_top, eminem_mid_top, eminem_recent_top))
colnames(eminem_top10_freq) <- c("word" ,"alltime", "early", "mid", "recent")
eminem_top10_freq_gather <- gather(eminem_top10_freq, key = "type", value = "frequency", -word)
eminem_top10_plot <- ggplot(eminem_top10_freq_gather, aes(x = type,y = frequency,fill = type)) +
geom_bar(position = "dodge", stat = "identity") + ylab("") +
facet_wrap( ~word, scales = "free", nrow = 2, ncol = 5) +
theme(axis.title.x = element_blank(),axis.text.x = element_blank(),axis.ticks.x=element_blank())+
ggtitle("Frequency change of top 10 words used across time")+labs(y="")+
theme(panel.spacing.x = unit(1, "cm"), panel.spacing.y = unit(1, "cm"))
eminem_top10_plot
plotly(wordcount1)
install.packages("BTYD")
library(BTYD)
df <- system.file("data/cdnowElog.csv", package = "BTYD")
df <-
df <- elog <- dc.ReadLines(cdnowElog, cust.idx = 2, date.idx = 3, sales.idx = 5)
df <- elog <- dc.ReadLines(df, cust.idx = 2, date.idx = 3, sales.idx = 5)
df <- system.file("data/cdnowElog.csv", package = "BTYD")
df <- elog <- dc.ReadLines(df, cust.idx = 2, date.idx = 3, sales.idx = 5)
df <- dc.ReadLines(df, cust.idx = 2, date.idx = 3, sales.idx = 5)
df <- system.file("data/cdnowElog.csv", package = "BTYD")
df <- dc.ReadLines(df, cust.idx = 2, date.idx = 3, sales.idx = 5)
View(df)
#Change date format
df$date <- as.Date(df$date, "%Y%m%d");
View(df)
#Change
df <- dc.MergeTransactionsOnSameDate(df)
View(df)
df <- system.file("data/cdnowElog.csv", package = "BTYD")
df <- dc.ReadLines(df, cust.idx = 2, date.idx = 3, sales.idx = 5)
#Change date format
df$date <- as.Date(df$date, "%Y%m%d")
#Change
df1 <- dc.MergeTransactionsOnSameDate(df)
View(df)
View(df1)
View(df1)
View(df1)
end.of.cal.period <- as.Date("1997-09-30")
df.cal <- df1[which(df1$date <= end.of.cal.period),]
df <- system.file("data/cdnowElog.csv", package = "BTYD")
df <- dc.ReadLines(df, cust.idx = 2, date.idx = 3, sales.idx = 5)
#Change date format
df$date <- as.Date(df$date, "%Y%m%d")
#If more than one purchase in a day, add the value together
df <- dc.MergeTransactionsOnSameDate(df)
end.of.cal.period <- as.Date("1997-09-30")
df.calbration <- df[which(df$date <= end.of.cal.period),]
split.data <- dc.SplitUpElogForRepeatTrans(df.calbration);
View(split.data)
clean.df <- split.data$repeat.trans.elog;
View(clean.df)
install.packages("shiny")
shinyServer(function(input, output) {
output$plot=renderPlot({
hist(faithful$eruptions, probability = TRUE, breaks = as.numeric(input$n_breaks),
xlab = "Duration (minutes)", main = "Geyser eruption duration")
dens <- density(faithful$eruptions, adjust = input$bw_adjust)
lines(dens, col = "blue")
})
})
library(shiny)
shinyServer(function(input, output) {
output$plot=renderPlot({
hist(faithful$eruptions, probability = TRUE, breaks = as.numeric(input$n_breaks),
xlab = "Duration (minutes)", main = "Geyser eruption duration")
dens <- density(faithful$eruptions, adjust = input$bw_adjust)
lines(dens, col = "blue")
})
})
shinyUI(
fluidPage(
sidebarPanel(
selectInput("n_breaks", label = "Number of bins:",
choices = c(10, 20, 35, 50), selected = 20),
sliderInput("bw_adjust", label = "Bandwidth adjustment:",
min = 0.2, max = 2, value = 1, step = 0.2)),
mainPanel(plotOutput("plot"))
))
ùrunApp(getwd())
runApp(getwd())
shinyApp()
sudo apt-get install gdebi-core
wget https://download3.rstudio.org/ubuntu-14.04/x86_64/shiny-server-1.5.7.907-amd64.deb
sudo gdebi shiny-server-1.5.7.907-amd64.deb
runApp(getwd("/Users/stefano/Documents/Columbia/Term3/Applied Data Science/Proj2"))
??runApp
shiny::runApp('Documents/Columbia/Term3/Applied Data Science/Proj2')
runApp('Documents/Columbia/Term3/Applied Data Science/Proj2')
library(shiny)
library(ggplot2)
library(rgdal)
library(dplyr)
load("../data/score_dist.RData") #df_result_omit
load("../data/Quarter_scores.RData") ##df_monthly
load("/data/score_dist.RData") #df_result_omit
runApp('Documents/GitHub/fall2019-proj2--sec2-grp9/app/prj2')
load("/data/score_dist.RData") #df_result_omit
quarter.scores <- read.csv(file="../output/Quarter_scores.csv")
quarter.scores <- read.csv("../output/Quarter_scores.csv")
quarter.scores <- read.csv("../output/Quarter_scores.csv/")
quarter.scores <- read.csv("../output/Quarter_scores.csv", header = T)
quarter.scores <- read.csv("..Quarter_scores.csv")
load(file="../output/Quarter_scores.RData")
load(file="../output/Quarter_scores.RData")
quarter.scores <- read.csv(ile="../output/Quarter_scores.csv")
quarter.scores <- read.csv(file="../output/Quarter_scores.csv")
load(file="score_dist.RData")
load(file="../output/Quarter_scores.RData")
quarter.scores <- read.csv(file="../output/Quarter_scores.csv")
quarter.scores <- read.csv(file="../output/Quarter_scores.csv")
?read.csv
quarter.scores <- read.csv("../output/Quarter_scores.csv")
quarter.scores <- read.csv("../output/Quarter_scores.csv")
load("score_dist.RData")
load("score_dist.RData")
load("score_dist.RData")
load("score_dist.RData")
shiny::runApp('Documents/GitHub/fall2019-proj2--sec2-grp9/app')
quarter.scores <- read.csv("../output/Quarter_scores.csv")
setwd("~/Documents/GitHub/fall2019-proj2--sec2-grp9/output")
quarter.scores <- read.csv("Quarter_scores.csv")
View(quarter.scores)
